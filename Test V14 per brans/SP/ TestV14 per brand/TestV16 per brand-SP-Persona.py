import streamlit as st
from PIL import Image
import requests
from io import BytesIO
import groq
from groq import Groq
import streamlit.components.v1 as components  # (kept in case you use it later)
import json
from typing import Optional, Dict, Any, List

# =========================
# Safe import for Word export
# =========================
try:
    from docx import Document
    HAS_DOCX = True
except ImportError:
    HAS_DOCX = False

# =========================
# Helpers
# =========================
def t(lang: str, en: str, ar: str) -> str:
    return en if lang == "English" else ar

def safe_get_image(src: str, width: int = 200):
    try:
        if src.startswith("http"):
            r = requests.get(src, timeout=8)
            r.raise_for_status()
            img = Image.open(BytesIO(r.content))
        else:
            img = Image.open(src)
        st.image(img, width=width)
    except Exception:
        st.warning("âš ï¸ Could not load image. Using placeholder.")
        st.image("https://via.placeholder.com/200x100.png?text=No+Image", width=width)

def extract_json(s: str) -> Optional[Dict[str, Any]]:
    """
    Safely extract and parse JSON from a string.
    1) Try direct parse
    2) Fallback to slice between first '{' and last '}'
    """
    if not isinstance(s, str) or not s.strip():
        return None
    # try direct
    try:
        return json.loads(s)
    except Exception:
        pass
    # fallback slice
    try:
        start = s.index("{")
        end = s.rindex("}") + 1
        return json.loads(s[start:end])
    except Exception:
        return None

def map_len_constraints(resp_len: str):
    if resp_len == "Short":
        return 3, 2, 18
    if resp_len == "Long":
        return 6, 4, 28
    return 4, 3, 22  # Medium

def render_structured_plan(data: Dict[str, Any], lang: str):
    """Renders a structured 'steps' style plan (if present)."""
    title = data.get("title") or t(lang, "Sales Call Plan", "Ø®Ø·Ø© Ø§Ù„Ø²ÙŠØ§Ø±Ø©")
    summary = data.get("summary") or ""
    steps = data.get("steps") or []
    closing = data.get("closing") or {}

    st.markdown(f"### {title}")
    if summary:
        st.markdown(f"> {summary}")

    for i, step in enumerate(steps, start=1):
        head = f"{t(lang, 'Step', 'Ø§Ù„Ø®Ø·ÙˆØ©')} {i}: {step.get('title','')}"
        with st.expander(head, expanded=(i == 1)):
            for key, label_en, label_ar in [
                ("goal", "Goal", "Ø§Ù„Ù‡Ø¯Ù"),
                ("talk_track", "Talk Track", "Ù†Øµ Ø§Ù„Ø­Ø¯ÙŠØ«"),
                ("evidence", "Evidence", "Ø§Ù„Ø¯Ù„ÙŠÙ„"),
                ("objection", "Objection Handling", "Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø§Ø¹ØªØ±Ø§Ø¶"),
                ("action", "Rep Action", "Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…Ù†Ø¯ÙˆØ¨"),
            ]:
                if step.get(key):
                    st.markdown(f"**{t(lang,label_en,label_ar)}:** {step[key]}")

    if closing:
        st.markdown("---")
        st.markdown(f"#### {t(lang,'Closing & Next Steps','Ø§Ù„Ø®ØªØ§Ù… ÙˆØ§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©')}")
        if closing.get("cta"):
            st.markdown(f"**{t(lang,'Call to Action','Ø§Ù„Ø¯Ø¹ÙˆØ© Ù„Ù„Ø¥Ø¬Ø±Ø§Ø¡')}:** {closing['cta']}")
        if closing.get("next_visit_plan"):
            st.markdown(f"**{t(lang,'Next Visit Plan','Ø®Ø·Ø© Ø§Ù„Ø²ÙŠØ§Ø±Ø© Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©')}:** {closing['next_visit_plan']}")
        metrics = closing.get("metrics") or []
        if metrics:
            st.markdown(f"**{t(lang,'Metrics to Track','Ù…Ø¤Ø´Ø±Ø§Øª Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©')}:** " + " â€¢ ".join(metrics))

def render_generic_bilingual(data: Dict[str, Any], lang: str):
    """Renders generic, dictionary-based bilingual sections (Probing Questions, Objections, etc.)."""
    st.markdown("### " + t(lang, "Generated Sales Call Plan (EN + AR)", "Ø§Ù„Ø®Ø·Ø© Ø§Ù„Ù…ÙˆÙ„Ø¯Ø© (Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ + Ø¹Ø±Ø¨ÙŠ)"))
    for section, content in data.items():
        st.markdown(f"#### {section}")
        if isinstance(content, list):
            for item in content:
                st.markdown(f"- {item}")
        elif isinstance(content, dict):
            for k, v in content.items():
                st.markdown(f"**{k}:** {v}")
        else:
            st.markdown(str(content))

# =========================
# App Setup
# =========================
st.set_page_config(page_title="AI Sales Call Assistant", layout="wide")

# Language selector
language = st.radio("Select Language / Ø§Ø®ØªØ± Ø§Ù„Ù„ØºØ©", options=["English", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"], horizontal=True)

st.title(t(language, "ğŸ§  AI Sales Call Assistant", "ğŸ§  Ù…Ø³Ø§Ø¹Ø¯ Ù…ÙƒØ§Ù„Ù…Ø§Øª Ø§Ù„Ù…Ø¨ÙŠØ¹Ø§Øª Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"))
st.caption(t(language,
             "Tailor your sales call plan based on persona, barriers, and segment.",
             "Ø®ØµØµ Ø®Ø·Ø© Ø§Ù„Ø²ÙŠØ§Ø±Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø´Ø®ØµÙŠØ© Ø§Ù„Ø·Ø¨ÙŠØ¨ ÙˆØ§Ù„Ø­ÙˆØ§Ø¬Ø² ÙˆØ§Ù„Ø´Ø±ÙŠØ­Ø©."))

# =========================
# Data / constants
# =========================
gsk_brands = {
    "Augmentin": "https://assets.gskinternet.com/pharma/GSKpro/Egypt/PDFs/pi.pdf",
    "Shingrix": "https://assets.gskinternet.com/pharma/GSKpro/Saudi/shingrix/shingrix-pi.pdf",
    "Seretide": "https://assets.gskinternet.com/pharma/GSKpro/Egypt/Seretide/seretide_pi_205223.pdf",
}
gsk_brands_images = {
    "Augmentin": "https://www.bloompharmacy.com/cdn/shop/products/augmentin-1-gm-14-tablets-145727_600x600_crop_center.jpg?v=1687635056",
    "Shingrix": "https://www.oma-apteekki.fi/WebRoot/NA/Shops/na/67D6/48DA/D0B0/D959/ECAF/0A3C/0E02/D573/3ad67c4e-e1fb-4476-a8a0-873423d8db42_3Dimage.png",
    "Seretide": "https://cdn.salla.sa/QeZox/eyy7B0bg8D7a0Wwcov6UshWFc04R6H8qIgbfFq8u.png",
}
race_segments = ["R â€“ Reach", "A â€“ Acquisition", "C â€“ Conversion", "E â€“ Engagement"]
doctor_barriers = [
    t(language, "1 - HCP does not consider HZ a risk", "1 - Ù„Ø§ ÙŠØ¹ØªØ¨Ø± Ø§Ù„Ø·Ø¨ÙŠØ¨ Ø§Ù„Ù‚ÙˆØ¨Ø§Ø¡ Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠØ© Ø®Ø·Ø±Ø§Ù‹"),
    t(language, "2 - No time", "2 - Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙˆÙ‚Øª"),
    t(language, "3 - Cost concern", "3 - Ù…Ø´ÙƒÙ„Ø© Ø§Ù„ØªÙƒÙ„ÙØ©"),
    t(language, "4 - Not convinced", "4 - ØºÙŠØ± Ù…Ù‚ØªÙ†Ø¹ Ø¨Ø§Ù„ÙØ¹Ø§Ù„ÙŠØ©"),
    t(language, "5 - Accessibility", "5 - ØµØ¹ÙˆØ¨Ø© Ø§Ù„ÙˆØµÙˆÙ„ (POVs)"),
]
objectives = [t(language,"Awareness","Ø§Ù„ØªÙˆØ¹ÙŠØ©"), t(language,"Adoption","Ø§Ù„ØªØ¨Ù†ÙŠ"), t(language,"Retention","Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ©")]
specialties = [
    t(language,"General Practitioner","Ø·Ø¨ÙŠØ¨ Ø£Ø³Ø±Ø©"),
    t(language,"Cardiologist","Ø·Ø¨ÙŠØ¨ Ù‚Ù„Ø¨"),
    t(language,"Dermatologist","Ø·Ø¨ÙŠØ¨ Ø¬Ù„Ø¯ÙŠØ©"),
    t(language,"Endocrinologist","Ø·Ø¨ÙŠØ¨ ØºØ¯Ø¯"),
    t(language,"Pulmonologist","Ø·Ø¨ÙŠØ¨ Ø±Ø¦Ø©"),
]
personas = [
    t(language,"Uncommitted Vaccinator","ØºÙŠØ± Ù…Ù„ØªØ²Ù… Ø¨Ø§Ù„ØªØ·Ø¹ÙŠÙ…"),
    t(language,"Reluctant Efficiency","ÙƒÙØ¡ Ù…ØªØ±Ø¯Ø¯"),
    t(language,"Patient Influenced","Ù…ØªØ£Ø«Ø± Ø¨Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø±ÙŠØ¶"),
    t(language,"Committed Vaccinator","Ù…Ù„ØªØ²Ù… Ø¨Ø§Ù„ØªØ·Ø¹ÙŠÙ…"),
]
personal_types_experience = [t(language,"Most Senior","Ø§Ù„Ø£ÙƒØ«Ø± Ø®Ø¨Ø±Ø©"), t(language,"Junior","Ù…Ø¨ØªØ¯Ø¦")]
personal_types_communication = [t(language,"Friendly","ÙˆØ¯ÙˆØ¯"), t(language,"Masked","Ù…ØªØ­ÙØ¸"), t(language,"Open","Ù…Ù†ÙØªØ­"), t(language,"Reserved","Ø±Ø²ÙŠÙ†")]
personal_types_mindset = [t(language,"Scientific","Ø¹Ù„Ù…ÙŠ"), t(language,"Emotional","Ø¹Ø§Ø·ÙÙŠ"), t(language,"Analytical","ØªØ­Ù„ÙŠÙ„ÙŠ"), t(language,"Pragmatic","Ø¹Ù…Ù„ÙŠ")]
gsk_approaches = [
    t(language,"Use data-driven evidence","Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ø¯Ù„Ø© Ø§Ù„Ù…Ø¨Ù†ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"),
    t(language,"Focus on patient outcomes","Ø±ÙƒØ² Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø±ÙŠØ¶"),
    t(language,"Leverage storytelling techniques","Ø§Ø³ØªØ®Ø¯Ù… Ø£Ø³Ø§Ù„ÙŠØ¨ Ø§Ù„Ø³Ø±Ø¯ Ø§Ù„Ù‚ØµØµÙŠ"),
]

# =========================
# Initialize Groq client
# =========================
client = Groq(api_key=st.secrets.get("GROQ_API_KEY", "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"))  # put your key in Streamlit secrets

# =========================
# Session state
# =========================
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "filters" not in st.session_state:
    st.session_state.filters = {
        "brand": None, "segment": None, "barrier": [],
        "objective": None, "specialty": None, "persona": None,
        "personal_type_exp": [], "personal_type_comm": [], "personal_type_mind": [],
        "response_length": "Medium", "response_tone": "Formal", "interface_mode": "Chatbot",
        "max_steps": 4, "max_bullets": 3, "strict_precision": True,
    }

def reset_selections():
    st.session_state.filters.update({
        "brand": None, "segment": None, "barrier": [],
        "objective": None, "specialty": None, "persona": None,
        "personal_type_exp": [], "personal_type_comm": [], "personal_type_mind": [],
        "response_length": "Medium", "response_tone": "Formal", "interface_mode": "Chatbot",
        "max_steps": 4, "max_bullets": 3, "strict_precision": True,
    })

# =========================
# Sidebar (bilingual)
# =========================
st.sidebar.header(t(language,"Filters & Options","Ø§Ù„Ù…Ø±Ø´Ø­Ø§Øª ÙˆØ§Ù„Ø®ÙŠØ§Ø±Ø§Øª"))
if st.sidebar.button("ğŸ”„ " + t(language, "Reset All Selections", "Ø¥Ø¹Ø§Ø¯Ø© Ø¶Ø¨Ø· Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±Ø§Øª")):
    reset_selections()

brand = st.sidebar.selectbox(t(language,"Brand","Ø§Ù„Ø¹Ù„Ø§Ù…Ø© Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ©"), list(gsk_brands.keys()))
segment = st.sidebar.selectbox(t(language,"RACE Segment","Ø´Ø±ÙŠØ­Ø© RACE"), race_segments)
barrier = st.sidebar.multiselect(t(language,"Doctor Barrier","Ø­ÙˆØ§Ø¬Ø² Ø§Ù„Ø·Ø¨ÙŠØ¨"), doctor_barriers)
objective = st.sidebar.selectbox(t(language,"Objective","Ø§Ù„Ù‡Ø¯Ù"), objectives)
specialty = st.sidebar.selectbox(t(language,"Specialty","Ø§Ù„ØªØ®ØµØµ"), specialties)
persona = st.sidebar.selectbox(t(language,"HCP Persona","Ø´Ø®ØµÙŠØ© Ø§Ù„Ø·Ø¨ÙŠØ¨"), personas)
personal_type_exp = st.sidebar.multiselect(t(language,"Experience Level","Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø¨Ø±Ø©"), personal_types_experience)
personal_type_comm = st.sidebar.multiselect(t(language,"Communication Style","Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„ØªÙˆØ§ØµÙ„"), personal_types_communication)
personal_type_mind = st.sidebar.multiselect(t(language,"Mindset","Ø§Ù„Ø¹Ù‚Ù„ÙŠØ©"), personal_types_mindset)
personal_type = personal_type_exp + personal_type_comm + personal_type_mind

response_length_options = ["Short","Medium","Long"]
response_tone_options = ["Formal","Casual","Friendly","Persuasive"]
response_length = st.sidebar.selectbox(t(language,"Response Length","Ø·ÙˆÙ„ Ø§Ù„Ø±Ø¯"), response_length_options)
response_tone = st.sidebar.selectbox(t(language,"Response Tone","Ù†Ø¨Ø±Ø© Ø§Ù„Ø±Ø¯"), response_tone_options)

max_steps_ui = st.sidebar.slider(t(language,"Max Steps","Ø£Ù‚ØµÙ‰ Ø¹Ø¯Ø¯ Ù„Ù„Ø®Ø·ÙˆØ§Øª"), 2, 6, st.session_state.filters["max_steps"])
max_bullets_ui = st.sidebar.slider(t(language,"Max Bullets/Step","Ø£Ù‚ØµÙ‰ Ù†Ù‚Ø§Ø· Ù„ÙƒÙ„ Ø®Ø·ÙˆØ©"), 1, 5, st.session_state.filters["max_bullets"])
strict_precision = st.sidebar.checkbox(t(language,"Strict Precision (very concise)","Ø¯Ù‚Ø© ØµØ§Ø±Ù…Ø© (Ù…Ø®ØªØµØ± Ø¬Ø¯Ù‹Ø§)"),
                                       value=st.session_state.filters["strict_precision"])
st.session_state.filters.update({"max_steps": max_steps_ui,"max_bullets": max_bullets_ui,"strict_precision": strict_precision})

interface_mode = st.sidebar.radio(t(language,"Interface Mode","ÙˆØ¶Ø¹ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©"),
                                  [t(language,"Chatbot","Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©"),
                                   t(language,"Card Dashboard","Ù„ÙˆØ­Ø© Ø§Ù„Ø¨Ø·Ø§Ù‚Ø§Øª"),
                                   t(language,"Flow Visualization","Ù…Ø®Ø·Ø· Ø§Ù„ØªØ¯ÙÙ‚")])

# Brand image
st.sidebar.markdown("â€”")
st.sidebar.markdown(f"**{t(language,'Brand Leaflet','ÙˆØ±Ù‚Ø© Ø§Ù„Ù…Ù†ØªØ¬')}:** [{brand}]({gsk_brands[brand]})")
safe_get_image(gsk_brands_images.get(brand, ""), width=180)

# =========================
# Main input
# =========================
user_input = st.text_area(t(language,"Type your message...","Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ..."), key="user_input", height=80)

# =========================
# Prompt builder (bilingual, detailed examples)
# =========================
def build_prompt() -> str:
    steps_limit_len, bullets_limit_len, max_words = map_len_constraints(response_length)
    steps_limit = min(steps_limit_len, st.session_state.filters["max_steps"])
    bullets_limit = min(st.session_state.filters["max_bullets"], 5)

    schema = {
        "Probing Questions": [
            "3â€“5 open-ended questions, each in EN + AR, with a short note on why it is effective."
        ],
        "Communication Style": "Detailed guidance with at least 2 doâ€™s and 2 donâ€™ts; include EN + AR phrasing tips.",
        "Objection Handling": {
            "Barrier Name": "Realistic doctor statement (EN + AR) + strong sample response (EN + AR) with supporting rationale."
        },
        "Key Messages": [
            "3â€“5 messages; each elaborated in 2â€“3 sentences with EN + AR examples."
        ],
        "Closing Strategy": "Detailed closing; EN + AR dialogue for commitment and next steps."
    }

    constraints = f"""
- Return ONLY a single JSON object following the schema below (no markdown, no backticks).
- Provide **bilingual output** (English + Arabic) for questions, objections, key messages, and closing dialogue.
- Be **descriptive and practical** with concrete examples suitable for a field sales rep.
- Sort/organize content logically; keep each individual item concise but informative.
- If unknown, omit the field/key entirely.
"""

    persona_style = ", ".join(personal_type) if personal_type else "None"
    approaches_str = "\n".join(gsk_approaches)

    prompt = f"""
You are a pharma sales coach. Create a **very detailed and descriptive bilingual (English + Arabic) sales call plan**.

Context:
- Brand: {brand}
- RACE Segment: {segment}
- Doctor Barriers: {', '.join(barrier) if barrier else 'None'}
- Objective: {objective}
- Specialty: {specialty}
- HCP Persona: {persona}
- HCP Personal Types: {persona_style}
- Response Tone: {response_tone}

Approved GSK Sales Approaches to reflect:
{approaches_str}

Agent/User input:
{user_input}

{constraints}

JSON Schema (descriptive):
{json.dumps(schema, ensure_ascii=False, indent=2)}
"""
    return prompt

# =========================
# Generate Plan
# =========================
go_label = "ğŸš€ " + t(language,"Generate Plan","Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø®Ø·Ø©")
if st.button(go_label) and user_input.strip():
    with st.spinner(t(language,"Generating AI response...","Ø¬Ø§Ø±Ù Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø¯...")):
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        prompt = build_prompt()
        response = client.chat.completions.create(
            model="meta-llama/llama-4-scout-17b-16e-instruct",
            messages=[
                {"role": "system", "content": t(language,
                                                "You are a helpful sales assistant that replies in English and Arabic where requested.",
                                                "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø¨ÙŠØ¹Ø§Øª Ù…ÙÙŠØ¯ ÙˆØªØ±Ø¯ Ø¨Ø§Ù„Ù„ØºØªÙŠÙ† Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ÙˆØ§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„Ø·Ù„Ø¨.")},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=1800
        )
        ai_raw = response.choices[0].message.content
        data = extract_json(ai_raw)

        # save to history (raw for debugging / parsed for reuse)
        st.session_state.chat_history.append({
            "role": "ai",
            "content": ai_raw if not data else json.dumps(data, ensure_ascii=False)
        })

        # render
        if data:
            st.success(t(language,"Structured plan generated.","ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø·Ø© Ù…ÙÙ†Ø¸Ù‘Ù…Ø©."))
            # Try to detect if it's "steps" style or generic bilingual structure
            if "steps" in data or "closing" in data or "summary" in data:
                render_structured_plan(data, language)
            else:
                render_generic_bilingual(data, language)

            # Download options
            if HAS_DOCX:
                try:
                    doc = Document()
                    doc.add_heading(t(language,"Sales Call Plan (EN + AR)","Ø®Ø·Ø© Ø§Ù„Ø²ÙŠØ§Ø±Ø© (Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ + Ø¹Ø±Ø¨ÙŠ)"), 0)

                    # write content smartly
                    def write_section(title, content):
                        doc.add_heading(str(title), level=1)
                        if isinstance(content, list):
                            for item in content:
                                doc.add_paragraph(f"- {item}")
                        elif isinstance(content, dict):
                            for k, v in content.items():
                                doc.add_paragraph(f"{k}: {v}")
                        else:
                            doc.add_paragraph(str(content))

                    if isinstance(data, dict):
                        for k, v in data.items():
                            write_section(k, v)
                    else:
                        doc.add_paragraph(str(data))

                    buf = BytesIO()
                    doc.save(buf)
                    buf.seek(0)
                    st.download_button(
                        t(language,"ğŸ“¥ Download Plan (Word)","ğŸ“¥ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ø®Ø·Ø© (ÙˆÙˆØ±Ø¯)"),
                        buf,
                        file_name="sales_call_plan_bilingual.docx",
                        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                    )
                except Exception:
                    st.warning(t(language,"Word export failed. Offering JSON instead.","ÙØ´Ù„ ØªØµØ¯ÙŠØ± Ù…Ù„Ù ÙˆÙˆØ±Ø¯. Ø³ÙŠØªÙ… ØªÙˆÙÙŠØ± JSON Ø¨Ø¯Ù„Ù‹Ø§ Ù…Ù†Ù‡."))
                    st.download_button(
                        t(language,"ğŸ“¥ Download Plan (JSON)","ğŸ“¥ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ø®Ø·Ø© (JSON)"),
                        json.dumps(data, ensure_ascii=False, indent=2),
                        file_name="sales_call_plan_bilingual.json",
                        mime="application/json"
                    )
            else:
                st.warning(t(language,"python-docx is not installed. Falling back to JSON download.",
                             "Ø­Ø²Ù…Ø© python-docx ØºÙŠØ± Ù…Ø«Ø¨ØªØ©. Ø³ÙŠØªÙ… ØªÙˆÙÙŠØ± Ø§Ù„ØªÙ†Ø²ÙŠÙ„ Ø¨ØµÙŠØºØ© JSON."))
                st.download_button(
                    t(language,"ğŸ“¥ Download Plan (JSON)","ğŸ“¥ ØªÙ†Ø²ÙŠÙ„ Ø§Ù„Ø®Ø·Ø© (JSON)"),
                    json.dumps(data, ensure_ascii=False, indent=2),
                    file_name="sales_call_plan_bilingual.json",
                    mime="application/json"
                )
        else:
            st.warning(t(language,"Could not parse structured JSON. Showing raw output:",
                         "ØªØ¹Ø°Ù‘Ø± ØªØ­Ù„ÙŠÙ„ JSON Ø§Ù„Ù…Ù†Ø¸Ù‘Ù…. Ø³ÙŠØªÙ… Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª Ø§Ù„Ù†ØµÙŠØ©:"))
            st.markdown(f"<div style='background:#f0f2f6; padding:12px; border-radius:10px'>{ai_raw}</div>", unsafe_allow_html=True)

# =========================
# Chat history (bilingual label)
# =========================
if st.session_state.chat_history:
    st.subheader(t(language,"ğŸ’¬ Chat History","ğŸ’¬ Ø³Ø¬Ù„Ù‘ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©"))
    for msg in st.session_state.chat_history:
        role = t(language, "ğŸ§‘â€ğŸ’¼ You", "ğŸ§‘â€ğŸ’¼ Ø£Ù†Øª") if msg["role"] == "user" else t(language, "ğŸ¤– Assistant", "ğŸ¤– Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯")
        st.markdown(f"**{role}:** {msg['content']}")
