import streamlit as st
import groq
from groq import Groq

client = Groq(api_key="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")  # Add your API key here

# Language Selection
language = st.selectbox("ğŸŒ Select Language / Ø§Ø®ØªØ± Ø§Ù„Ù„ØºØ©:", ["English", "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"])

# Translations dictionary
translations = {
    "English": {
        "title": "ğŸ§  AI Sales Call Assistant",
        "description": "Prepare for HCP visits with AI-powered suggestions.",
        "select_segment": "Select Doctor Segment:",
        "select_behavior": "Select Doctor Behavior:",
        "select_objective": "Select Visit Objective:",
        "generate": "Generate AI Suggestions",
        "loading": "Generating recommendations...",
        "result_title": "ğŸ¤– AI Recommendations",
        "segments": ["Evidence-Seeker", "Skeptic", "Time-Pressured", "Early Adopter", "Traditionalist"],
        "behaviors": ["Scientific", "Skeptical", "Passive", "Emotional", "Argumentative"],
        "objectives": ["Awareness", "Objection Handling", "Follow-up", "New Launch", "Reminder"],
        "system_prompt": "You are an expert pharma sales assistant AI.",
        "user_prompt": """
            You are an expert pharma sales assistant AI.

            Based on:
            - Segment: {segment}
            - Behavior: {behavior}
            - Visit Objective: {objective}

            Suggest the following for the GSK Brand Augmentin:
            1. Three probing questions the rep should ask the doctor.
            2. Recommended communication style for this profile.
            3. Most suitable sales module.

            Be specific, concise, and practical.
        """
    },
    "Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©": {
        "title": "ğŸ§  Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø²ÙŠØ§Ø±Ø§Øª Ø§Ù„Ø·Ø¨ÙŠØ© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
        "description": "Ø§Ø³ØªØ¹Ø¯ Ù„Ø²ÙŠØ§Ø±Ø© Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡ Ø¨Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ù…Ø¯Ø¹ÙˆÙ…Ø© Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.",
        "select_segment": "Ø§Ø®ØªØ± Ù†ÙˆØ¹ Ø§Ù„Ø·Ø¨ÙŠØ¨:",
        "select_behavior": "Ø§Ø®ØªØ± Ø³Ù„ÙˆÙƒ Ø§Ù„Ø·Ø¨ÙŠØ¨:",
        "select_objective": "Ø§Ø®ØªØ± Ù‡Ø¯Ù Ø§Ù„Ø²ÙŠØ§Ø±Ø©:",
        "generate": "Ø§Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª",
        "loading": "Ø¬Ø§Ø±ÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª...",
        "result_title": "ğŸ¤– Ø§Ù‚ØªØ±Ø§Ø­Ø§Øª Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
        "segments": ["Ø¨Ø§Ø­Ø« Ø¹Ù† Ø§Ù„Ø£Ø¯Ù„Ø©", "Ù…Ø´ÙÙƒÙ‘Ùƒ", "Ù…Ø¶ØºÙˆØ· Ø¨Ø§Ù„ÙˆÙ‚Øª", "Ù…ÙØ¨ÙƒØ± Ø§Ù„ØªØ¨Ù†ÙŠ", "ØªÙ‚Ù„ÙŠØ¯ÙŠ"],
        "behaviors": ["Ø¹Ù„Ù…ÙŠ", "Ù…Ø´ÙÙƒÙ‘Ùƒ", "Ø³Ù„Ø¨ÙŠ", "Ø¹Ø§Ø·ÙÙŠ", "Ù…Ø¬Ø§Ø¯Ù„"],
        "objectives": ["Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ÙˆØ¹ÙŠ", "Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø§Ø¹ØªØ±Ø§Ø¶Ø§Øª", "Ù…ØªØ§Ø¨Ø¹Ø©", "Ø¥Ø·Ù„Ø§Ù‚ Ø¬Ø¯ÙŠØ¯", "ØªØ°ÙƒÙŠØ±"],
        "system_prompt": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø®Ø¨ÙŠØ± ÙÙŠ Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.",
        "user_prompt": """
            Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø®Ø¨ÙŠØ± ÙÙŠ Ù…Ø¨ÙŠØ¹Ø§Øª Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ù…Ø¯Ø¹ÙˆÙ… Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.

            Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰:
            - Ù†ÙˆØ¹ Ø§Ù„Ø·Ø¨ÙŠØ¨: {segment}
            - Ø³Ù„ÙˆÙƒ Ø§Ù„Ø·Ø¨ÙŠØ¨: {behavior}
            - Ù‡Ø¯Ù Ø§Ù„Ø²ÙŠØ§Ø±Ø©: {objective}

            Ø§Ù‚ØªØ±Ø­ Ø§Ù„ØªØ§Ù„ÙŠ:
            1. Ø«Ù„Ø§Ø«Ø© Ø£Ø³Ø¦Ù„Ø© Ø§Ø³ØªÙƒØ´Ø§ÙÙŠØ© ÙŠÙ…ÙƒÙ† Ù„Ù„Ù…Ù†Ø¯ÙˆØ¨ Ø·Ø±Ø­Ù‡Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ø·Ø¨ÙŠØ¨.
            2. Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„Ø£Ù†Ø³Ø¨ Ù„Ù‡Ø°Ø§ Ø§Ù„Ù†ÙˆØ¹ Ù…Ù† Ø§Ù„Ø£Ø·Ø¨Ø§Ø¡.
            3. Ø§Ù„ÙˆØ­Ø¯Ø© Ø§Ù„Ø¨ÙŠØ¹ÙŠØ© Ø§Ù„Ø£Ù†Ø³Ø¨ Ù„Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø©.

            Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ù„Ø±Ø¯ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙ‚Ø·ØŒ ÙˆÙƒÙ† Ù…Ø­Ø¯Ø¯Ù‹Ø§ ÙˆØ¹Ù…Ù„ÙŠÙ‹Ø§.
        """
    }
}

# Load language dictionary
t = translations[language]

# UI
st.title(t["title"])
st.markdown(t["description"])

segment = st.selectbox(t["select_segment"], t["segments"])
behavior = st.selectbox(t["select_behavior"], t["behaviors"])
objective = st.selectbox(t["select_objective"], t["objectives"])

if st.button(t["generate"]):
    with st.spinner(t["loading"]):
        prompt = t["user_prompt"].format(segment=segment, behavior=behavior, objective=objective)

        response = client.chat.completions.create(
            model="meta-llama/llama-4-scout-17b-16e-instruct",
            messages=[
                {"role": "system", "content": t["system_prompt"]},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )

        ai_output = response.choices[0].message.content
        st.subheader(t["result_title"])
        st.markdown(ai_output)
